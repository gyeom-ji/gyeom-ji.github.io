---
title: "캐시 메모리"
author: gyeomji
date: 2024-07-05 10:00:00 +0900
categories: [Computer Architecture]
tags: [Cache Memory]
pin: false
math: true
mermaid: true
---

<br/> 

## 캐시 메모리 (Cache Memory)

---

- CPU의 처리 속도와 주기억장치의 접근 속도 차이를 줄이기 위해 사용한다.
  - 중앙처리장치의 속도가 저장장치에 비해서 고속이므로 저장장치의 읽기와 쓰기 동작과정 동안 기다려야 한다.
  - 이런 문제를 극복하기 위해 중앙처리장치의 처리속도만큼 빠른 저장장치인 캐시 메모리가 등장했다.
- DRAM보다 빠른 SRAM으로 CPU에 자주 쓰이는 명령어와 데이터를 저장하여 처리 성능을 높인다.
- 캐시 메모리는 메모리 계층 구조에서 가장 빠른 소자이며, 처리속도가 거의 CPU의 속도와 비슷하다.
- 메인 메모리에서 자주 사용하는 프로그램과 데이터를 저장해둬 속도를 빠르게 한다.
  - CPU가 어떤 데이터를 원하는지 예측할 수 있어야 한다.
  - 작은 용량의 캐시 메모리가 CPU가 이후에 참조할 정보를 어느 정도 가진지에 따라 캐시의 성능이 결정되기 때문이다.
  - 이를 위해 캐시의 지역성(Locality)을 이용한다.
- 캐시 메모리의 동작은 참조의 지역성(locality of reference)에 의해 가능하다.
  - 지역성을 활용하여 메인 메모리에 있는 데이터를 캐시 메모리에 불러와 두고, 프로세서가 필요한 데이터를 캐시 메모리에서 먼저 찾도록 하여 시스템 성능을 향상할 수 있다.
  - 주 기억장치를 접근하는 횟수가 줄어들어 처리속도가 향상된다.
- 캐시의 전반적인 성능은 일반적으로 캐시 메모리의 논리적 구성에 영향을 많이 받는다.

![cacheMemory](/assets/img/cacheMemory.png)

<br/>

## Cache Memory 동작 순서

---

![cacheMemory](/assets/img/cacheMemory1.png)

<br/>

## 주기억장치와 캐시 메모리간 정보 공유

---

![cacheMemory](/assets/img/cacheMemory2.png)

- 주기억장치에 저장된 데이터의 일부가 블록 단위로 캐시 메모리에 복사된다.
- CPU가 적중된 데이터들을 워드 단위로 캐시 메모리에서 읽어온다.

<br/>

### 주기억장치와 캐시 메모리의 구조

---

- 주기억장치에서 하나의 번지에 저장되는 데이터의 단위는 word이다.
- word가 여러 개 모여 하나의 Block이 되며 이 Block이 캐시로 인출되는 정보의 그룹이다.

![mainCacheMemory](/assets/img/mainCacheMemory.png)

- 캐시 메모리에서 슬롯 Slot은 한 블록이 저장되는 장소다.
- 블록은 캐시 메모리 각 슬롯에 저장되는 데이터의 길이가 된다.

<br/>

### Cache Block

---

- 캐시 메모리가 가지는 데이터 그룹 단위이다.
- 각각의 캐시 블록은 데이터를 담고 있으며 캐시 태그와 묶어 하나의 캐시 슬롯(엔트리)을 구성한다.
- 태그는 캐시 블록의 고유 식별 값으로 CPU 프로세서는 캐시 태그 값을 통해 캐시 블록에 접근할 수 있다.
  - 빈번하게 사용되는 데이터의 주소들이 흩어져 있기 때문에 캐시에 저장하는 데이터에는 태그가 필요하다.
- 캐시 태그에는 해당 캐시 블록에 올바른 데이터가 저장되어 있다는 것을 나타내는 유효 비트(Valid bit)가 포함되어 있다.
- 캐시 블록이 비어 있거나 올바르지 않은 값을 가지면 유효 비트는 0으로 설정되어 유효한 블록이 없다는 것을 알려준다.
- 캐시 라인에 따라 캐시 메모리의 논리적인 구조가 구분된다.
  > 캐시 라인 : 캐시에 데이터가 저장될 때, 묶이는 기본적인 단위다. 캐시 라인은 CPU가 캐시 메모리에서 목적 데이터를 바로 접근하기 위해 만들어졌다.
- 필요한 캐시 메모리 크기는 메모리에 존재하는 캐시 블록의 전체 개수와 블록 하나당 크기로 계산한다.
  - 캐시 태그는 필요한 캐시 메모리의 크기와 별도로 요구되는 공간이다.
  > ex) 32KB 캐시 = 32KB 데이터를 저장할 수 있는 캐시 메모리<br/>
  > 이 메모리 크기에 캐시 태그 크기는 포함되어 있지 않다. 캐시 블록 크기가 32 byte일 때 캐시 태그가 태그 필드 17bit, 유효 비트 1bit를 가진다고 가정한다. 32KB 캐시 메모리에는 32byte 캐시 블록이 1024개 들어있다. 한 캐시 블록당 18비트의 캐시 태그를 가지므로 총 18 * 104 = 18Kb 메모리를 더 가지고 있다. 즉 32KB캐시는 2.25KB 메모리를 더 가지고 있다.
  - 캐시 태그로 인한 메모리는 캐시 블록과 상관없는 오버헤드로 취급된다.
  - 태크 오버헤드가 증가할수록 데이터 엑세스에 대한 대기 Latency가 증가한다. 
  - 태그 오버헤드로 인한 대기를 줄이기 위해 CPU 프로세서는 태그를 확인하는 과정과 데이터에 접근하는 과정을 동시에 수행한다.

![cacheBlock](/assets/img/cacheBlock.png)

> 캐시가 빠른 이유는 참조 지역성의 원리에 따라 자주 사용하는 데이터를 우선적으로 저장하고 있기 때문이기도 하지만 유효비트와 태그필드를 이용한 메모리 접근으로 인하여 시간 복잡도가 O(1)일 정도로 작아지기 때문이다.


<br/>

## 메모리 접근

---

- 찾고자 하는 데이터의 메모리 주소는 캐시 메모리에서 먼저 이용된다.
  - 찾고 있는 데이터가 캐시 블록에 있는지 여부를 식별하는데 사용한다.
- 메모리 주소는 올바른 캐시 블록을 식별할 수 있도록 캐시 태그, 세트(슬롯) 인덱스, 블록 오프셋으로 구성된다.
  - 블록 오프셋은 캐시 블록 내 특정 바이트 위치에 접근하기 위한 필드다.


![cacheMemoryAddress](/assets/img/cacheMemoryAddress.png)

- 32 bit CPU 프로세서가 Direct Mapped 캐시 메모리에 접근한 경우

![cacheMemoryAddress](/assets/img/cacheMemoryAddress1.png)

- CPU 프로세서에 접근해야 할 메모리 주소가 지정되면 이 주소를 필요한 필드로 분할하고 캐시 메모리의 엔트리를 검사한다.
  - 세트 인덱스에 따른 캐시 엔트리에 접근한다.
  - 해당 캐시 엔트리의 유효 비트가 1인지 확인한다.
  - 1일 경우 메모리 주소의 태그 필드와 캐시 엔트리의 태그 필드가 동일한지 비교한다.
  - 두 개의 태그가 동일할 경우 유효비트와 AND 연산한다.
- 유효비트가 1인 경우 캐시 블록에 올바른 데이터가 존재한다는 것을 의미한다.
- CPU에 지정된 메모리 주소의 태그와 캐시 엔트리의 태그가 같으므로 올바른 메모리 주소에 접근되었음을 확인할 수 있다.
- 이것이 바로 Cache Hit 이다.
- 유효비트가 0일 경우 Cache Miss가 발생한다.
  - 캐시 블록이 비었거나 올바르지 않은 데이터가 있다는 뜻이다.
- 캐시 메모리는 상위 캐시 메모리나 주기억장치에서 데이터를 다시 가져와 작성한 후 유효비트를 1로 변경한다.
- 유효비트가 1이여도 태그가 일치하지 않으면 Cache Miss가 발생한다.
  - 캐시 메모리의 교체 정책에 따라 조치가 이루어진다.


<br/>

## 캐시 메모리 용어

---


### 적중 Hit 

- CPU가 주기억장치에 접근하기 전에 캐시 메모리에 원하는 데이터가 존재하는 경우
- Hit rate : CPU가 요청한 데이터 중 캐시에 저장된 비율
- 적중률(Hit Ratio) : 캐시 메모리를 가진 컴퓨터의 성능을 나타내는 척도로 적중률이 높을수록 속도가 향상된다.
  - 적중률 =  캐시 메모리 적중 횟수 / 전체 메모리 참조 횟수 * 100
- Hit time : 캐시에서 데이터를 읽어오는 데 필요한 시간

<br/>

### 부적중 Miss 

- CPU가 요청한 데이터가 캐시 메모리에 없는 경우
- 부적중이 발생하면 메모리 저장소로부터 필요한 데이터를 찾아 캐시 메모리에 로드한다.
- Miss rate : CPU가 요청한 데이터 중 캐시에 저장되지 않은 비율 (= 1 - Hit rate)
- Miss penalty : miss가 발생해 데이터를 block만큼 메인 메모리에서 캐시 메모리로 가져오는 데 필요한 시간

<br/>

### Cache miss 종류

#### cold miss

- 해당 메모리 주소를 처음 불렀기 때문에 miss가 발생하는 경우이다. 
- cache가 비워져있었기 때문에 어쩔 수 없이 발생한다.

#### conflict miss 

- 캐시 메모리에 A 데이터와 B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 miss가 발생하는 경우이다.
- A 데이터를 저장한 후, B 데이터가 같은 캐시 메모리 주소에 할당되어 저장되면 이후에 A 데이터를 읽어오려고 했을 때 miss가 발생한다.

#### capacity miss 

- 캐시 메모리에 공간이 부족해서 miss가 발생하는 경우이다.


<br/>

## 캐시 지역성 Cache Locality

---

- 데이터에 대한 접근이 시간적 혹은 공간적으로 가깝게 발생하는 것이다.
- 캐시의 적중률(Hit rate)을 극대화하여 캐시가 효율적으로 동작할 수 있도록 한다.
- 프로그램은 모든 코드나 데이터를 균등하게 접근하지 않는다는 특성을 기본으로 한다.
- 캐시의 지역성은 공간 지역성(Spatial Locality)과 시간 지역성(Temporal Locality)으로 나뉜다.
- 시간 지역성을 고려하여 메모리 상 같은 주소에 접근할 때는 연속적으로 접근하는게 더 좋고, 메모리 주소를 오름차순이나 내림차순으로 접근하는 것이 더 좋을 수 있다.

<br/>

### 공간 지역성 

- 최근에 사용한 데이터와 인접한 데이터가 참조될 가능성이 높다는 특성
  - ex) 배열
  - A[0], A[1]과 같은 연속 접근의 경우 그다음 원소들에 접근할 가능성이 높다. 

### 시간 지역성 

- 최근에 사용한 데이터가 재참조될 가능성이 높은 특성
  - ex) for, while 과 같은 반복문에 사용되는 조건 변수
  - 반복문에서 사용하는 조건 변수처럼 한 번 참조된 데이터를 또 참조하게 될 가능성을 의미한다.


<br/>


## 캐시 메모리 설계 시 고려할 요소

---

### 1. 캐시 메모리 크기 

- 캐시 메모리의 용량이 클수록 주기억장치의 많은 블록을 복사해 저장할 수 있으므로 적중률이 높아진다.
- 용량이 커질수록 주소 해독 및 정보 인출을 위한 주변 회로가 복잡해져 접근 시간이 길어진다.
- 용량이 증가했다고 속도가 향상되는 것은 아니다.
- 결과적으로 캐시기억장치의 용량과 주변회로 간의 복잡도 관계를 최적화하여 적중률을 향상시키고 접근시간에 대한 저하를 막는 용량을 결정해야 한다.

<br/>

### 2. 인출 방식 Fetch algorithm

- 주기억장치에서 캐시메모리로 명령이나 데이터 블록을 인출해오는 방식에 따라 적중률이 많이 변한다.
- 요구 인출 방식 Demand Fetch : CPU가 현재 필요한 정보만 주기억장치에서 블록 단위로 인출해 오는 방식이다.
  - 매번 주기억장치에서 인출을 수행하므로 실패율이 높아져 캐시 메모리의 효과를 얻지 못할 수도 있다.
- 선인출 방식 Prefetch : CPU가 현재 필요한 정보 외에도 앞으로 필요할 것으로 예측되는 정보를 미리 인출하여 캐시 메모리에 저장하는 방식이다.
  - 주기억장치에서 명령, 데이터를 인출할 때 이웃한 위치에 있는 정보를 함께 인출해 캐시에 적재하는 방식으로 지역성이 높은 경우 효과가 좋다.

<br/>

### 3. 사상 함수 Mapping function

#### [ 사상의 개념 ]

![cacheMapping](/assets/img/cacheMapping.png)

- 캐시 메모리에서 인출이 실패하면 캐시 메모리의 일부분은 주기억장치로 옮기고 주기억장치에서 필요한 정보를 캐시메모리에 옮기는 정보 교환이 이뤄진다.
- 이렇게 주기억장치와 캐시 메모리 사이에서 정보를 옮기는 것을 mapping이라 한다.
- 캐시 메모리의 사상 방법에는 대표적으로 직접 사상 Direct Mapped, 연관 사상 Associative, 집합 연관 사상 Set Associative이 존재한다.

<br/>

#### Direct Mapped Cache 직접 사상 캐시 메모리

- 직접 매핑으로 메인 메모리를 일정한 크기의 블록으로 나눠 각 블록을 캐시의 정해진 위치에 매핑하는 방식이다.
  - 캐시 슬롯 0에 블록 0, 캐시 슬롯 1에 블록 1, 캐시 슬롯 2에 블록 2, 캐시 슬롯 3에 블록 3, 다시 캐시 슬롯 0에 블록 4 ... 과 같이 1:1로 직접 매핑한다.
  - 각 블록은 지정된 캐시 라인에만 저장될 수 있다.
- hit인지 miss인지 판단하기 위해 한 개의 라인(해당 블록이 적재될 수 있는 라인)만 확인하면 된다.
- 사상 과정이 간단하고 작은 용량의 RAM을 캐시기억장치로 사용하기 때문에 비용이 저렴하다.
  - 최소한의 전력으로 빠르게 작동한다.

<br/>

##### [ 직접 사상에서 주기억장치의 주소 형식]

![directMapping](/assets/img/directMapping2.png)

- 태그 필드는 태그 번호를 나타낸다.
- 슬롯(캐시 라인) 번호는 캐시 메모리에서 총 슬롯의 수 $m \ = \ 2^s$ 중 하나를 지정하는 번호이다.
- 단어 필드는 각 블록 내의 $2^w$ 개 단어들 중 하나를 선택한다.
- CPU가 요구하는 주기억장치의 주소 중 태그 필드와 슬롯 필드에 해당되는 캐시영역에서 슬롯 필드와 태그 필드를 비교해 동일하면 적중한다.
- 동일 슬롯 번호를 가지고 있지만 태그가 다른 두 개 이상의 단어가 반복하여 접근되면 적중률이 상당히 떨어지는 단점이 발생한다.

<br/>

##### [ 모듈로 modulo 연산 ]

- 주기억장치의 블록 j가 적재될 수 있는 캐시 슬롯의 번호 i는 모듈로 (modulo) 연산에 의해서 결정한다.
  - $ i \ = \ j \ mod \ m $
  - m : 캐시 슬롯의 전체 수
- 모듈로 연산은 나머지를 구하는 연산이다.
  - ex) 5 mod 3 = 2, 3 mod 7 = 3, 2 mod 7 = 2, 8 mod 2 = 0
- 캐시 슬롯은 주기억장치의 블록들을 공유하여 저장한다. 
- 이때 같은 슬롯을 공유하는 주기억장치 블록들은 서로 다른 태그를 가지게 된다.
- 캐시 슬롯이 공유할 수 있는 주기억장치의 블록들

  ![modulo](/assets/img/modulo.png){: width="300" height="300"}

<br/>

##### [ 직접 사상의 동작 ]

> 블록의 word 수가 1개이고 CPU가 00001번지 word를 필요로 하는 경우

![directMapping](/assets/img/directMapping3.png)

1. CPU는 2비트의 태그 정보 00과, 3비트의 캐시기억장치의 주소(슬롯 번호) 001를 동시에 표시한 00001를 캐시기억장치에 전달한다.
  - 캐시기억장치는 오직 001번지 주소만을 참조하고, 해당 번지가 비어 있으므로 실패(miss) 상태가 된다.
2. 캐시 실패를 확인하고 주기억장치에서 00001번지를 참조하여서 단어를 획득한다.
3. 획득한 단어는 캐시기억장치의 해당 주소에 데이터 1234와 태그 00을 저장한다.
4. 다시 단어 1234를 CPU에 전달한다.

<br/>

> CPU가 00010번지 word를 필요로 하는 경우

![directMapping](/assets/img/directMapping4.png)

1. 처음의 2비트 00은 태그를 나타내고, 다음 3비트 010은 캐시기억장치의 주소를 나타낸다.
  - 캐시기억장치의 010번지 주소만을 참조한다. 
  - 해당 번지가 비어 있으므로 실패(miss)한 것 으로 판단하고 주기억장치를 참조한다.
2. 주기억장치의 주소 00010에서 필요한 단어를 획득한다.
3. 캐시기억장치의 해당 주소 010에 단어 데이터 5678과 태그 00을 저장한다.
4. 단어 데이터 5678을 CPU로 전달한다.

<br/>

> CPU가 10001번지 word를 필요로 하는 경우

![directMapping](/assets/img/directMapping5.png)

1. 처음 2비트 10은 태그를 표시하고, 다음 3비트 001은 캐시기억장치의 주소를 나타낸다.
  - 캐시기억장치의 001번지에 접근하는데, 태그가 00으로 불일치하므로 실패한다.
2. 주기억장치 10001번지에서 단어를 획득한다.
3. 캐시기억장치의 001번지에 단어 데이터 7890과 태그10을 저장한다.
  - 태그를 포함해서 00 1234가 10 7890으로 변경된다.
4. 단어 데이터 7890이 CPU로 전달된다.

<br/>

> CPU가 00010번지 word를 필요로 하는 경우

![directMapping](/assets/img/directMapping6.png)

1. 처음의 2비트 00은 태그를 표시하고, 다음 3비트 010은 캐시기억장치의 주소를 나타낸다.
  - 캐시기억장치의 주소 010번지만 참고하는데, 태그가 00으로 일치하므로 적중한 것으로 판단한다.
2. 캐시기억장치 010번지에서 중앙처리장치가 요구하는 단어를 획득하게 된다.

<br/>

> 주기억장치 용량 : 128바이트, 블록 크기 : 4바이트, 캐시기억장치 크기 : 32바이트, 캐시 슬롯 크기 : 4바이트<br/>
> 직접 사상에 의해 데이터가 캐시기억장치에 저장되는 과정

![directMapping](/assets/img/directMapping.png)

- 전체 캐시 슬롯의 수는 캐시의 크기 32바이트를 캐시 슬롯의 크기 4바이트로 나눠 8개로 결정된다.
  - 블록 내의 단어 수가 1개이기 때문에 단어 필드는 항상 00이 된다.
- 동일한 슬롯 번호를 가지고 있지만 태그가 다른 두 개 이상의 단어가 반복하여 접근되면 적중률이 상당히 떨어지는 단점이 발생한다.
  - 여러 데이터가 동일한 라인에 저장되기를 원하기 때문이다.
- 프로그램이 동일한 라인에 적재되는 두 블록을 반복적으로 접근하는 경우 계속 캐시 실패가 발생해서 실패율이 현격하게 높아질 수 있다.
  - Associative 캐시를 사용한다.

<br/>

#### Associative Cache 연관 캐시 메모리

- 직접 사상 캐시 메모리의 단점을 보완한 것으로 주기억장치의 블록을 캐시 메모리의 어느 라인에든 적재할 수 있다.
- 가장 빠르고 융통성 있는 구조이다.
- 적중 검사가 모든 라인에 대해 이뤄지므로 검사 시간이 길어진다.
- 모든 캐시 슬롯의 태그 번호들을 고속으로 검색하기 위한 복잡한 회로가 필요하다.

<br/>

##### [ 연관 사상에서 주기억장치의 주소 형식 ]

![associativeMapping](/assets/img/associativeMapping.png)

- 태그 필드가 주기억장치의 블록 번호를 나타낸다.
- 캐시 메모리의 정해진 슬롯 번호에 저장되는 것이 아닌 임의로 저장될 수 있다.
- 따라서 슬롯 번호를 위한 필드는 존재하지 않는다.
- 단어 필드는 블록 내 존재하는 단어를 선택하는데 사용된다.
  - 블록 내 하나의 단어만 존재할 경우 단어 필드의 모든 비트는 0이 된다.
  - 그 이상의 단어 번호가 존재할 필요가 없기 때문이다.
- 주기억장치의 주소 태그와 단어 데이터가 캐시 메모리에 저장되므로 캐시 단어의 크기는 주기억장치 주소 태그 t와 단어당 데이터 비트 수의 합이 된다.

<br/>

##### [ 연관 사상의 동작 ]

![associativeMapping](/assets/img/associativeMapping1.png)

- 주기억장치에 저장된 단어들은 임의 위치의 캐시 메모리에 저장한다.
- 태그 필드는 4비트이고 단어 필드는 2필드지만 블록 내 한 개의 단어만 존재하므로 모두 00으로 되어있다.
- 캐시 메모리에서는 태그와 데이터를 저장하고 있는 것을 확인할 수 있다.
- CPU가 주기억장치에 저장된 단어들을 인출하려면 먼저 캐시 메모리에 대해 하나하나 검색을 수행하고 캐시 적중이 발생하면 인출 할 수 있다.
- 모든 지역을 검색해도 원하는 데이터가 존재하지 않을 경우 캐시 미스가 된다.
- 이 경우 주기억장치에서 원하는 데이터를 얻을 수 있다.

![associativeMapping1](/assets/img/associativeMapping2.png){: width="200" height="200"}

- CPU에서 나온 주기억장치의 주소를 레지스터에서 태그 부분만 비교하여 캐시가 적중이면 해당 주소 번지의 데이터를 읽어 CPU로 전송한다.
- 태그 필드와 단어 필드로 구성된 캐시 메모리와 주기억장치의 주소 즉, 태그 필드와 단어 필드가 저장되어 있는 인수(Fetch) 레지스터를 통해서 태그 부분만을 비교해서 원하는 번지의 데이터를 찾는다.
- 캐시 메모리가 꽉 차 있는 경우, 현재 필요 없는 부분을 캐시 메모리에서 제거하고 방금 읽어들인 데이터와 주소를 캐시 메모리에 저장하거나 라운드 로빈(round-robin) 방식을 이용한다.

<br/>

#### Set Associative Cache 집합 연관 캐시 메모리

- Direct Mapping과 Associative Mapping의 장점을 결합한 방식이다. 
- 집합 번호는 같고 태그가 다른 두 개 이상의 단어를 저장할 수 있는 구조를 가진다.
  - 주기억장치 블록 그룹이 하나의 캐시 집합을 공유하며, 그 집합에는 두 개 이상의 슬롯을 적재할 수 있다.
- 캐시는 v개의 집합들로 나누어지며, 각 집합들은 k개의 슬롯들로 구성된다.
- 캐시 슬롯의 총 수 m과 주기억장치 블록이 적재될 수 있는 캐시 집합 번호 i를 구하면 다음과 같다.
  - $ m \ = \ v \ * \ k, \ i \ = \ j \ mod \ v $
  - j : 주기억장치의 블록 번호

<br/>

##### [ 집합 연관 사상에서 주기억장치의 주소 형식 ]

![setassociativeMapping](/assets/img/setassociativeMapping.png)

- 태그 필드와 집합 필드를 합한 (t + d)비트가 주기억장치의 $2^{(t+d)}$블록들 중 하나를 지정하게 된다.

<br/>

##### [ 두 개의 집합을 갖는 집합 연관 캐시 메모리의 구조 ]

![setassociativeMapping](/assets/img/setassociativeMapping1.png)

- 집합 연관 캐시 메모리는 집합 1과 집합 2, 두 개의 집합으로 구분되며 집합 번호 000에 서로 다른 태그 00, 01로 구분되는 2개의 데이터가 동시에 저장되어 있다.
- 동일 집합 번호, 다른 태그 번호를 가지고 캐시 메모리에 접근하는 경우 직접 사상의 개념(동일 슬롯, 다른 태그)에서는 실패되었지만 집합 연관 사상 방식에서는 적중된다.
- 각 집합 내 슬롯에 저장되는 데이터는 직접 사상이 아니고 연관 사상 방식이 적용되어 블록 위치를 자유롭게 선택할 수 있다.
- 결과적으로 집합의 위치를 선택하는 것은 직접 사상 방법을 따르고 집합 내의 슬롯을 선택하는 것은 연관 사상법을 따른다.

<br/>

##### [ 집합 연관 사상의 동작 ]

> 주기억장치 용량: 128바이트, 블록 크기 : 4바이트, 캐시 크기 : 32바이트, 캐시슬롯 크기 : 약 8바이트


![setassociativeMapping](/assets/img/setassociativeMapping1.png)

- 캐시 메모리는 동일한 집합에 태그 값이 다른 두 종류의 데이터를 저장한다.
- 주소의 태그 필드 내용과 그 집합 내의 태그들을 비교하여 일치하는 것이 있으면 캐시 적중이 된다.
  - 일치하는 것이 없다면 캐시 실패가 된다.
- 실패 시 주기억장치에서 블록을 인출하고 캐시 메모리의 정해진 집합의 슬롯들 중에서 하나를 선택해 기존 블록을 제거하고 새로운 블록을 저장한다.
- 이 과정에서 기존의 슬롯들 중에서 어느 슬롯을 선택하느냐의 교체 알고리즘이 필요하다.

<br/>

### 4. 교체 알고리즘 Replacement algorithm

- 캐시 메모리의 모든 슬롯이 데이터로 채워진 상태에서 캐시 실패일 때 사용한다.
- 캐시 실패일 경우 캐시 메모리의 특정 슬롯에서 데이터를 제거하고 주기억장치에서 새로운 데이터 블록을 가져와야 한다.
- 캐시 메모리의 어느 슬롯 데이터를 제거하는가를 결정하는 방식이 교체 알고리즘이다.
- 직접 사상 방식에서는 주기억장치의 데이터가 캐시기억장치의 동일 슬롯에 저장되기 때문에 교체 알고리즘을 사용할 필요가 없다.
- 연관 사상 및 집합 연관 사상 방식의 경우 교체 알고리즘이 필요하다.
- 교체 알고리즘의 대표적인 종류에는 LRU (최소 최근 사용 알고리즘), LFU (최소 사용 빈도 알고리즘), FIFO (선입력 선출력 알고리즘), RANDOM (랜덤)이 있다.

<br/>

#### 최소 최근 사용(LRU, Least Recently Used) 알고리즘

- 현재까지 알려진 교체 알고리즘 중에서 가장 효과적인 교체 알고리즘으로 집합 연관 사상에서 사용되는 방식이다.
- CPU로의 인출이 없는 가장 오래 저장되어 있던 블록을 교체하는 방식이다.

#### 최소 사용 빈도(LFU, Least Frequently Used) 알고리즘

- 적재된 블록들 중에서 인출 횟수가 가장 적은 블록을 교체하는 방식이다.
- 최소 최근 사용 알고리즘이 시간적으로 오랫동안 사용되지 않은 블록을 교체하는 것이라면, 최소 사용 빈도 알고리즘은 사용된 횟수가 적은 블록을 교체하는 방식이다.

#### 선입력 선출력(FIFO, First In First Out) 알고리즘

- 가장 먼저 적재된 블록을 우선적으로 캐시기억장치에서 삭제하는 교체 방식이다.
- 캐시기억장치에 적재된 가장 오래된 블록이 삭제되고 새로운 블록이 적재된다.
- 구현이 용이하지만 시간적으로 오래된 블록을 교체하여 효율성을 보장하지 못한다.

#### 랜덤(Random)

- 캐시기억장치에서 임의의 블록을 선택하여 삭제하고 새로운 블록으로 교체하는 방식이다. 
- 효율성을 보장하기가 어렵다.

<br/>

### 5. 쓰기 정책 Write policy

- CPU가 프로그램을 실행하는 동안 연산 결과를 캐시기억장치에 기록하는 경우가 발생한다. 
- 이때 캐시기억장치와 주기억장치에 저장된 데이터가 상이하게 존재하므로 주기억장치의 데이터를 갱신하는 절차가 필요하다.

![writePolicy](/assets/img/writePolicy.png)

<br/>

#### 즉시 쓰기 Write-though 방식

- 중앙처리장치(CPU)에서 생성되는 데이터를 캐시기억장치와 주기억장치에 동시에 기록한다.
- CPU의 연산 결과를 기억장치에 저장하는 쓰기 동작은 캐시기억장치뿐만 아니라 주기억장치에서도 동시에 발생하기 때문에 데이터의 일관성을 쉽게 보장할 수 있다.
- 매번 쓰기 동작이 발생할 때마다 캐시기억장치와 주기억장치간 접근이 빈번 하게 일어나고 쓰기 시간이 길어지게 된다.

#### 나중 쓰기 Write-back 방식

- 캐시기억장치에 기록한 후, 기록된 블록에 대한 교체가 일어날 때 주기억장치에 기록한다.
- 새롭게 생성된 중앙처리장치의 데이터를 캐시기억장치에만 기록하고 주기억장치에는 나중에 기록하는 방식이다.
- 1비트의 태그를 이용하여 갱신된 캐시기억장치의 블록을 표시한다.
- 새로운 블록에 의해 캐시기억장치에서 삭제되어 교체되기 전에 주기억장치로 복사된다.
- 두 기억장치의 데이터가 서로 일치하지 않아 주기억장치가 무효상태로 존재한다. 
- 이 경우 주기억장치의 접근은 금지되고 캐시기억장치에만 접근된다.
- 즉시 쓰기 방식과 달리 주기억장치에 기록하는 동작을 최소할 수 있다.

<br/>

### 6. 블록 크기 Block policy

- 동시에 인출되는 정보들의 블록이 커지면 한꺼번에 많은 정보를 읽어 올 수 있지만 블록 인출시간이 길어지게 된다.
- 블록이 커질수록 캐시기억장치에 적재할 수 있는 블록의 수가 감소하기 때문에 블록들이 더 빈번히 교체된다.
- 블록이 커질수록 멀리 떨어진 단어들도 같이 읽혀오기 때문에 가까운 미래에 사용될 가능성이 낮다.
- 일반적인 블록의 크기는 4 ~ 8단어가 적당하다.

<br/>

### 7. 캐시 메모리 수 Number of caches

- 일반적인 시스템은 오직 하나의 캐시기억장치를 가지고 있었다.
- 최근에는 캐시기억장치들이 계층적 구조로 설치되거나 기능별로 분리된 다수의 캐시기억장치를 사용하는 것이 보편화 되었다.
- 캐시기억장치를 설계할 때에는 몇 계층으로 할 것인지를 결정하여야 하며, 통합 형태와 분리 형태 중에서 어떤 형태로 구성할 것인지를 결정해야 한다.

![writePolicy](/assets/img/numberOfCaches.png)

- (a) 단계 : 가장 일반적인 구조로 한 개의 캐시기억장치를 사용한다.
- (b) 단계 : 두 개의 캐시기억장치를 이용하여 계층적으로 구성한 구조다.
  - 캐시 1은 중앙처리장치에 내장되어 있는 경우가 일반적이다.
- (c) 단계 : 캐시기억장치 3개를 이용하여 계층적 구조로 설계한 것이다. 
  - (b)와 비교해서 캐시 1에 해당하는 부분이 분리된 형태의 두 개의 캐시로 발전되었다.
  - 각 기능에 따라서 명령어 캐시와 자료 캐시로 분리되었다. 
  - 하지만 (b)와 마찬가지로 캐시 1에 해당하는 명령어 캐시와 자료 캐시는 CPU에 내장되어 있는 캐시기억장치다.


<br/>
<br/>

[^footnote]: The footnote source
[^fn-nth-2]: The 2nd footnote source
